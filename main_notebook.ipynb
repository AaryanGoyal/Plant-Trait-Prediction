{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xQyyU9UMId2r"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/Colab Notebooks/Kaggle/cs-480-2024-spring.zip' /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_Qq-RB5IgaV",
        "outputId": "b61a1dfe-f99e-429d-b424-d8f141e18fdb"
      },
      "outputs": [],
      "source": [
        "!unzip cs-480-2024-spring.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7JYL3A9Ig9F",
        "outputId": "d30338eb-e6f2-4ebf-d072-39f0a0ca0e8d"
      },
      "outputs": [],
      "source": [
        "pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTeJMl-DIkXu",
        "outputId": "906dfaa3-ebe9-49bc-b953-5c9b2cbb7100"
      },
      "outputs": [],
      "source": [
        "pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcDaAx_YH8Tf",
        "outputId": "5c4ccde3-b147-4ebb-f2a8-61e464b64171"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
            "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
            "  warnings.warn(\"xFormers is not available (Attention)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
            "  warnings.warn(\"xFormers is not available (Block)\")\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitg14/dinov2_vitg14_reg4_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vitg14_reg4_pretrain.pth\n",
            "100%|██████████| 4.23G/4.23G [01:14<00:00, 61.2MB/s]\n",
            "Extracting Image Embeddings in Batches: 100%|██████████| 1356/1356 [2:05:14<00:00,  5.54s/it]\n",
            "Extracting Image Embeddings in Batches: 100%|██████████| 200/200 [18:29<00:00,  5.55s/it]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import timm\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from catboost import CatBoostRegressor\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load ancillary data\n",
        "train_df = pd.read_csv('data/train.csv')\n",
        "test_df = pd.read_csv('data/test.csv')\n",
        "\n",
        "# Ensure the 'id' column in train_df and test_df is of type string\n",
        "train_df['id'] = train_df['id'].astype(str)\n",
        "test_df['id'] = test_df['id'].astype(str)\n",
        "\n",
        "# List all image paths based on the original data\n",
        "train_images_dir = 'data/train_images'\n",
        "test_images_dir = 'data/test_images'\n",
        "\n",
        "train_image_paths = [os.path.join(train_images_dir, f\"{img_id}.jpeg\") for img_id in train_df['id'].values]\n",
        "test_image_paths = [os.path.join(test_images_dir, f\"{img_id}.jpeg\") for img_id in test_df['id'].values]\n",
        "\n",
        "# Check if CUDA is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the DINOv2 model using torch.hub and move it to the GPU if available\n",
        "model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14_reg').to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define augmentation pipeline\n",
        "augmentation_pipeline = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjusted to match the input size for the model\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "def load_and_preprocess_images(image_paths, transform):\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = transform(img)\n",
        "        images.append(img)\n",
        "    return torch.stack(images).to(device)\n",
        "\n",
        "def extract_vit_embeddings_batch(image_paths, model, batch_size=32):\n",
        "    embeddings = []\n",
        "    for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Extracting Image Embeddings in Batches\"):\n",
        "        batch_paths = image_paths[i:i+batch_size]\n",
        "        batch_images = load_and_preprocess_images(batch_paths, augmentation_pipeline)\n",
        "        with torch.no_grad():\n",
        "            batch_embeddings = model(batch_images).cpu().numpy()\n",
        "        embeddings.extend(batch_embeddings)\n",
        "    return np.array(embeddings)\n",
        "\n",
        "# Extract embeddings for all train and test images in batches\n",
        "train_image_embeddings = extract_vit_embeddings_batch(train_image_paths, model, batch_size=32)\n",
        "test_image_embeddings = extract_vit_embeddings_batch(test_image_paths, model, batch_size=32)\n",
        "\n",
        "# Create DataFrame for image embeddings\n",
        "train_image_feature_df = pd.DataFrame(train_image_embeddings, index=train_df['id'].values, columns=[f'img_feat_{i}' for i in range(train_image_embeddings.shape[1])])\n",
        "test_image_feature_df = pd.DataFrame(test_image_embeddings, index=test_df['id'].values, columns=[f'img_feat_{i}' for i in range(test_image_embeddings.shape[1])])\n",
        "\n",
        "# Merge image embeddings with ancillary data\n",
        "train_full_feature_df = pd.merge(train_df, train_image_feature_df, left_on='id', right_index=True)\n",
        "test_full_feature_df = pd.merge(test_df, test_image_feature_df, left_on='id', right_index=True)\n",
        "\n",
        "# Select all columns for ancillary features (1 to 163) and image embeddings (from 170 onward)\n",
        "X = train_full_feature_df.iloc[:, 1:164].join(train_full_feature_df.iloc[:, 170:]).values  # Features: ancillary + image embeddings\n",
        "y = train_df.iloc[:, 164:170].values\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDofzFAv851W"
      },
      "outputs": [],
      "source": [
        "np.save('dino_train_embeddings.npy', train_image_embeddings)\n",
        "np.save('dino_test_embeddings.npy', test_image_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxTd3V5UIWyl",
        "outputId": "9b9a472b-9ea9-4435-cbc8-3f0622cbd9a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training XGBoost Models: 100%|██████████| 6/6 [23:57<00:00, 239.58s/it]\n"
          ]
        }
      ],
      "source": [
        "# Train XGBoost models\n",
        "xgboost_models = [xgb.XGBRegressor(n_estimators=1500, learning_rate=0.1, max_depth=8, objective='reg:squarederror',  tree_method = \"hist\", device = \"cuda\") for _ in range(6)]\n",
        "xgboost_predictions_val = []\n",
        "\n",
        "for i in tqdm(range(6), desc=\"Training XGBoost Models\"):\n",
        "    xgboost_models[i].fit(X_train, y_train[:, i])\n",
        "    xgboost_predictions_val.append(xgboost_models[i].predict(X_val))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgUt9y4SIVEZ",
        "outputId": "a449d3e3-b5a6-491e-e2c0-8188fcff2535"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining LightGBM Models:   0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.050799 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 431034\n",
            "[LightGBM] [Info] Number of data points in the train set: 34690, number of used features: 1699\n",
            "[LightGBM] [Info] Start training from score 1.036130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining LightGBM Models:  17%|█▋        | 1/6 [12:16<1:01:20, 736.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.888451 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 431034\n",
            "[LightGBM] [Info] Number of data points in the train set: 34690, number of used features: 1699\n",
            "[LightGBM] [Info] Start training from score 148.331981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining LightGBM Models:  33%|███▎      | 2/6 [24:17<48:30, 727.61s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.924319 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 431034\n",
            "[LightGBM] [Info] Number of data points in the train set: 34690, number of used features: 1699\n",
            "[LightGBM] [Info] Start training from score 19701.660189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining LightGBM Models:  50%|█████     | 3/6 [36:01<35:49, 716.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.735263 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 431034\n",
            "[LightGBM] [Info] Number of data points in the train set: 34690, number of used features: 1699\n",
            "[LightGBM] [Info] Start training from score 3482.081355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining LightGBM Models:  67%|██████▋   | 4/6 [47:35<23:35, 707.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.674433 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 431034\n",
            "[LightGBM] [Info] Number of data points in the train set: 34690, number of used features: 1699\n",
            "[LightGBM] [Info] Start training from score 15.111195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining LightGBM Models:  83%|████████▎ | 5/6 [59:21<11:47, 707.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.749783 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 431034\n",
            "[LightGBM] [Info] Number of data points in the train set: 34690, number of used features: 1699\n",
            "[LightGBM] [Info] Start training from score 399128.072384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training LightGBM Models: 100%|██████████| 6/6 [1:11:05<00:00, 710.92s/it]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train LightGBM models with GPU support\n",
        "lightgbm_models = [lgb.LGBMRegressor(n_estimators=1500, learning_rate=0.1) for _ in range(6)]\n",
        "lightgbm_predictions_val = []\n",
        "\n",
        "for i in tqdm(range(6), desc=\"Training LightGBM Models\"):\n",
        "    lightgbm_models[i].fit(X_train, y_train[:, i])\n",
        "    lightgbm_predictions_val.append(lightgbm_models[i].predict(X_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmxAMJXmIThO",
        "outputId": "b6504e8a-7dd8-41d0-80aa-a4745d5f2899"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining CatBoost Models:   0%|          | 0/6 [00:00<?, ?it/s]Warning: less than 75% gpu memory available for training. Free: 8925.0625 Total: 15102.0625\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.1339849\ttest: 0.1350534\tbest: 0.1350534 (0)\ttotal: 622ms\tremaining: 15m 32s\n",
            "100:\tlearn: 0.1006300\ttest: 0.1082108\tbest: 0.1082108 (100)\ttotal: 48.1s\tremaining: 11m 5s\n",
            "200:\tlearn: 0.0939557\ttest: 0.1059489\tbest: 0.1059489 (200)\ttotal: 1m 32s\tremaining: 9m 55s\n",
            "300:\tlearn: 0.0891647\ttest: 0.1047983\tbest: 0.1047983 (300)\ttotal: 2m 14s\tremaining: 8m 57s\n",
            "400:\tlearn: 0.0850538\ttest: 0.1041561\tbest: 0.1041561 (400)\ttotal: 2m 58s\tremaining: 8m 8s\n",
            "500:\tlearn: 0.0815046\ttest: 0.1036296\tbest: 0.1036296 (500)\ttotal: 3m 41s\tremaining: 7m 21s\n",
            "600:\tlearn: 0.0781212\ttest: 0.1030955\tbest: 0.1030908 (598)\ttotal: 4m 24s\tremaining: 6m 36s\n",
            "700:\tlearn: 0.0752208\ttest: 0.1026979\tbest: 0.1026979 (700)\ttotal: 5m 7s\tremaining: 5m 50s\n",
            "800:\tlearn: 0.0724929\ttest: 0.1024238\tbest: 0.1024213 (799)\ttotal: 5m 50s\tremaining: 5m 5s\n",
            "900:\tlearn: 0.0699885\ttest: 0.1022207\tbest: 0.1022207 (900)\ttotal: 6m 33s\tremaining: 4m 21s\n",
            "1000:\tlearn: 0.0678439\ttest: 0.1020323\tbest: 0.1020297 (997)\ttotal: 7m 15s\tremaining: 3m 36s\n",
            "1100:\tlearn: 0.0658287\ttest: 0.1019338\tbest: 0.1019296 (1098)\ttotal: 7m 57s\tremaining: 2m 53s\n",
            "1200:\tlearn: 0.0638667\ttest: 0.1017696\tbest: 0.1017696 (1200)\ttotal: 8m 39s\tremaining: 2m 9s\n",
            "1300:\tlearn: 0.0621843\ttest: 0.1016697\tbest: 0.1016697 (1300)\ttotal: 9m 21s\tremaining: 1m 25s\n",
            "1400:\tlearn: 0.0604560\ttest: 0.1015630\tbest: 0.1015630 (1400)\ttotal: 10m 3s\tremaining: 42.7s\n",
            "1499:\tlearn: 0.0587788\ttest: 0.1014924\tbest: 0.1014910 (1497)\ttotal: 10m 45s\tremaining: 0us\n",
            "bestTest = 0.1014910054\n",
            "bestIteration = 1497\n",
            "Shrink model to first 1498 iterations.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining CatBoost Models:  17%|█▋        | 1/6 [11:21<56:47, 681.53s/it]Warning: less than 75% gpu memory available for training. Free: 8925.0625 Total: 15102.0625\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 6.7774734\ttest: 6.8095600\tbest: 6.8095600 (0)\ttotal: 633ms\tremaining: 15m 48s\n",
            "100:\tlearn: 5.1733128\ttest: 5.5136138\tbest: 5.5136138 (100)\ttotal: 48.1s\tremaining: 11m 6s\n",
            "200:\tlearn: 4.8409569\ttest: 5.4121626\tbest: 5.4121626 (200)\ttotal: 1m 31s\tremaining: 9m 50s\n",
            "300:\tlearn: 4.5901328\ttest: 5.3687613\tbest: 5.3687502 (299)\ttotal: 2m 14s\tremaining: 8m 55s\n",
            "400:\tlearn: 4.3816990\ttest: 5.3406836\tbest: 5.3406836 (400)\ttotal: 2m 57s\tremaining: 8m 5s\n",
            "500:\tlearn: 4.2025242\ttest: 5.3160710\tbest: 5.3160710 (500)\ttotal: 3m 39s\tremaining: 7m 17s\n",
            "600:\tlearn: 4.0421294\ttest: 5.3017980\tbest: 5.3016658 (597)\ttotal: 4m 21s\tremaining: 6m 31s\n",
            "700:\tlearn: 3.8890773\ttest: 5.2883907\tbest: 5.2883907 (700)\ttotal: 5m 4s\tremaining: 5m 46s\n",
            "800:\tlearn: 3.7546236\ttest: 5.2775280\tbest: 5.2775280 (800)\ttotal: 5m 46s\tremaining: 5m 2s\n",
            "900:\tlearn: 3.6357616\ttest: 5.2693526\tbest: 5.2693526 (900)\ttotal: 6m 27s\tremaining: 4m 17s\n",
            "1000:\tlearn: 3.5138333\ttest: 5.2614898\tbest: 5.2614898 (1000)\ttotal: 7m 10s\tremaining: 3m 34s\n",
            "1100:\tlearn: 3.3985040\ttest: 5.2509079\tbest: 5.2508304 (1095)\ttotal: 7m 52s\tremaining: 2m 51s\n",
            "1200:\tlearn: 3.3002089\ttest: 5.2450803\tbest: 5.2436887 (1171)\ttotal: 8m 33s\tremaining: 2m 7s\n",
            "1300:\tlearn: 3.2146358\ttest: 5.2408796\tbest: 5.2408796 (1300)\ttotal: 9m 14s\tremaining: 1m 24s\n",
            "1400:\tlearn: 3.1272844\ttest: 5.2350578\tbest: 5.2350578 (1400)\ttotal: 9m 56s\tremaining: 42.1s\n",
            "1499:\tlearn: 3.0453169\ttest: 5.2319717\tbest: 5.2317930 (1484)\ttotal: 10m 37s\tremaining: 0us\n",
            "bestTest = 5.231793009\n",
            "bestIteration = 1484\n",
            "Shrink model to first 1485 iterations.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining CatBoost Models:  33%|███▎      | 2/6 [22:34<45:06, 676.51s/it]Warning: less than 75% gpu memory available for training. Free: 8925.0625 Total: 15102.0625\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 4.1472702\ttest: 4.0812729\tbest: 4.0812729 (0)\ttotal: 579ms\tremaining: 14m 28s\n",
            "100:\tlearn: 2.6034550\ttest: 2.8147015\tbest: 2.8147015 (100)\ttotal: 47.6s\tremaining: 10m 59s\n",
            "200:\tlearn: 2.3788192\ttest: 2.7791819\tbest: 2.7790733 (199)\ttotal: 1m 30s\tremaining: 9m 44s\n",
            "300:\tlearn: 2.2057596\ttest: 2.7622349\tbest: 2.7622349 (300)\ttotal: 2m 12s\tremaining: 8m 49s\n",
            "400:\tlearn: 2.0628063\ttest: 2.7453909\tbest: 2.7453270 (399)\ttotal: 2m 55s\tremaining: 8m 2s\n",
            "500:\tlearn: 1.9426868\ttest: 2.7355841\tbest: 2.7355841 (500)\ttotal: 3m 38s\tremaining: 7m 16s\n",
            "600:\tlearn: 1.8339024\ttest: 2.7287259\tbest: 2.7287259 (600)\ttotal: 4m 21s\tremaining: 6m 30s\n",
            "700:\tlearn: 1.7315664\ttest: 2.7196225\tbest: 2.7196225 (700)\ttotal: 5m 3s\tremaining: 5m 46s\n",
            "800:\tlearn: 1.6484695\ttest: 2.7147135\tbest: 2.7146175 (798)\ttotal: 5m 46s\tremaining: 5m 2s\n",
            "900:\tlearn: 1.5719502\ttest: 2.7108324\tbest: 2.7108006 (890)\ttotal: 6m 28s\tremaining: 4m 18s\n",
            "1000:\tlearn: 1.4991558\ttest: 2.7080356\tbest: 2.7079604 (999)\ttotal: 7m 11s\tremaining: 3m 34s\n",
            "1100:\tlearn: 1.4394125\ttest: 2.7066304\tbest: 2.7065796 (1085)\ttotal: 7m 52s\tremaining: 2m 51s\n",
            "1200:\tlearn: 1.3828215\ttest: 2.7020090\tbest: 2.7019821 (1198)\ttotal: 8m 34s\tremaining: 2m 7s\n",
            "1300:\tlearn: 1.3272324\ttest: 2.6987862\tbest: 2.6987525 (1299)\ttotal: 9m 16s\tremaining: 1m 25s\n",
            "1400:\tlearn: 1.2769794\ttest: 2.6982394\tbest: 2.6977257 (1393)\ttotal: 9m 58s\tremaining: 42.3s\n",
            "1499:\tlearn: 1.2332150\ttest: 2.6932947\tbest: 2.6932947 (1499)\ttotal: 10m 38s\tremaining: 0us\n",
            "bestTest = 2.693294718\n",
            "bestIteration = 1499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining CatBoost Models:  50%|█████     | 3/6 [33:50<33:48, 676.15s/it]Warning: less than 75% gpu memory available for training. Free: 8925.0625 Total: 15102.0625\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 66.0860625\ttest: 65.1477491\tbest: 65.1477491 (0)\ttotal: 618ms\tremaining: 15m 26s\n",
            "100:\tlearn: 50.5178944\ttest: 57.3415171\tbest: 57.3415171 (100)\ttotal: 46s\tremaining: 10m 36s\n",
            "200:\tlearn: 45.2422377\ttest: 57.1039638\tbest: 57.1039638 (200)\ttotal: 1m 28s\tremaining: 9m 30s\n",
            "300:\tlearn: 41.2014645\ttest: 56.9366275\tbest: 56.9118191 (295)\ttotal: 2m 10s\tremaining: 8m 39s\n",
            "400:\tlearn: 37.9383427\ttest: 56.8696921\tbest: 56.8591565 (398)\ttotal: 2m 51s\tremaining: 7m 50s\n",
            "500:\tlearn: 35.2936436\ttest: 56.8104233\tbest: 56.7726019 (488)\ttotal: 3m 32s\tremaining: 7m 3s\n",
            "600:\tlearn: 33.2316468\ttest: 56.7977371\tbest: 56.7726019 (488)\ttotal: 4m 12s\tremaining: 6m 17s\n",
            "700:\tlearn: 31.3292339\ttest: 56.7491217\tbest: 56.7253472 (656)\ttotal: 4m 53s\tremaining: 5m 34s\n",
            "800:\tlearn: 29.7135202\ttest: 56.7730122\tbest: 56.7253472 (656)\ttotal: 5m 33s\tremaining: 4m 51s\n",
            "900:\tlearn: 28.3472883\ttest: 56.7187246\tbest: 56.7155634 (874)\ttotal: 6m 13s\tremaining: 4m 8s\n",
            "1000:\tlearn: 27.0213052\ttest: 56.7146649\tbest: 56.7025226 (978)\ttotal: 6m 54s\tremaining: 3m 26s\n",
            "1100:\tlearn: 25.9319219\ttest: 56.7355520\tbest: 56.6982705 (1035)\ttotal: 7m 34s\tremaining: 2m 44s\n",
            "1200:\tlearn: 25.0533636\ttest: 56.7167080\tbest: 56.6982705 (1035)\ttotal: 8m 14s\tremaining: 2m 3s\n",
            "1300:\tlearn: 24.2748816\ttest: 56.7161184\tbest: 56.6982705 (1035)\ttotal: 8m 54s\tremaining: 1m 21s\n",
            "1400:\tlearn: 23.5240559\ttest: 56.6787814\tbest: 56.6771824 (1398)\ttotal: 9m 34s\tremaining: 40.6s\n",
            "1499:\tlearn: 22.8411954\ttest: 56.6919091\tbest: 56.6645478 (1454)\ttotal: 10m 13s\tremaining: 0us\n",
            "bestTest = 56.66454781\n",
            "bestIteration = 1454\n",
            "Shrink model to first 1455 iterations.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining CatBoost Models:  67%|██████▋   | 4/6 [44:40<22:11, 665.84s/it]Warning: less than 75% gpu memory available for training. Free: 8925.0625 Total: 15102.0625\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.5830389\ttest: 0.5959107\tbest: 0.5959107 (0)\ttotal: 590ms\tremaining: 14m 44s\n",
            "100:\tlearn: 0.4706864\ttest: 0.5131795\tbest: 0.5131795 (100)\ttotal: 47.9s\tremaining: 11m 3s\n",
            "200:\tlearn: 0.4405814\ttest: 0.5057743\tbest: 0.5057726 (199)\ttotal: 1m 31s\tremaining: 9m 53s\n",
            "300:\tlearn: 0.4179110\ttest: 0.5013489\tbest: 0.5013489 (300)\ttotal: 2m 15s\tremaining: 8m 58s\n",
            "400:\tlearn: 0.3995557\ttest: 0.4983643\tbest: 0.4983398 (398)\ttotal: 2m 57s\tremaining: 8m 6s\n",
            "500:\tlearn: 0.3825981\ttest: 0.4959363\tbest: 0.4959363 (500)\ttotal: 3m 39s\tremaining: 7m 18s\n",
            "600:\tlearn: 0.3673403\ttest: 0.4942846\tbest: 0.4942846 (600)\ttotal: 4m 22s\tremaining: 6m 32s\n",
            "700:\tlearn: 0.3526498\ttest: 0.4926736\tbest: 0.4926574 (696)\ttotal: 5m 5s\tremaining: 5m 48s\n",
            "800:\tlearn: 0.3400903\ttest: 0.4914163\tbest: 0.4914163 (800)\ttotal: 5m 47s\tremaining: 5m 3s\n",
            "900:\tlearn: 0.3278293\ttest: 0.4903967\tbest: 0.4903922 (899)\ttotal: 6m 30s\tremaining: 4m 19s\n",
            "1000:\tlearn: 0.3170176\ttest: 0.4894530\tbest: 0.4894530 (1000)\ttotal: 7m 12s\tremaining: 3m 35s\n",
            "1100:\tlearn: 0.3071137\ttest: 0.4886198\tbest: 0.4885885 (1096)\ttotal: 7m 54s\tremaining: 2m 51s\n",
            "1200:\tlearn: 0.2969217\ttest: 0.4879161\tbest: 0.4879161 (1200)\ttotal: 8m 37s\tremaining: 2m 8s\n",
            "1300:\tlearn: 0.2884812\ttest: 0.4875263\tbest: 0.4874582 (1293)\ttotal: 9m 19s\tremaining: 1m 25s\n",
            "1400:\tlearn: 0.2800113\ttest: 0.4873151\tbest: 0.4873076 (1393)\ttotal: 10m 1s\tremaining: 42.5s\n",
            "1499:\tlearn: 0.2727490\ttest: 0.4869007\tbest: 0.4868444 (1483)\ttotal: 10m 42s\tremaining: 0us\n",
            "bestTest = 0.4868444375\n",
            "bestIteration = 1483\n",
            "Shrink model to first 1484 iterations.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining CatBoost Models:  83%|████████▎ | 5/6 [55:58<11:10, 670.30s/it]Warning: less than 75% gpu memory available for training. Free: 8925.0625 Total: 15102.0625\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 2213.2243723\ttest: 2135.4450335\tbest: 2135.4450335 (0)\ttotal: 618ms\tremaining: 15m 27s\n",
            "100:\tlearn: 1616.6180507\ttest: 1713.6141079\tbest: 1713.6141079 (100)\ttotal: 46.4s\tremaining: 10m 42s\n",
            "200:\tlearn: 1483.8709870\ttest: 1696.5594408\tbest: 1696.5352225 (198)\ttotal: 1m 28s\tremaining: 9m 32s\n",
            "300:\tlearn: 1379.7298407\ttest: 1687.1669368\tbest: 1687.1669368 (300)\ttotal: 2m 10s\tremaining: 8m 39s\n",
            "400:\tlearn: 1300.5809462\ttest: 1682.4933023\tbest: 1681.9631933 (397)\ttotal: 2m 51s\tremaining: 7m 50s\n",
            "500:\tlearn: 1231.5904992\ttest: 1677.5886281\tbest: 1677.5886281 (500)\ttotal: 3m 33s\tremaining: 7m 4s\n",
            "600:\tlearn: 1173.4193478\ttest: 1675.4056597\tbest: 1674.9213832 (593)\ttotal: 4m 14s\tremaining: 6m 20s\n",
            "700:\tlearn: 1128.0237988\ttest: 1672.7107236\tbest: 1672.7107236 (700)\ttotal: 4m 54s\tremaining: 5m 35s\n",
            "800:\tlearn: 1084.3512112\ttest: 1671.1206151\tbest: 1671.1206151 (800)\ttotal: 5m 34s\tremaining: 4m 52s\n",
            "900:\tlearn: 1045.9263922\ttest: 1669.2194967\tbest: 1669.2194967 (900)\ttotal: 6m 15s\tremaining: 4m 9s\n",
            "1000:\tlearn: 1010.1361288\ttest: 1667.6723616\tbest: 1667.6310152 (991)\ttotal: 6m 55s\tremaining: 3m 27s\n",
            "1100:\tlearn: 976.2847327\ttest: 1665.9001293\tbest: 1665.7342070 (1092)\ttotal: 7m 35s\tremaining: 2m 45s\n",
            "1200:\tlearn: 945.7971021\ttest: 1664.4857516\tbest: 1663.9969490 (1164)\ttotal: 8m 16s\tremaining: 2m 3s\n",
            "1300:\tlearn: 918.4569189\ttest: 1663.3448231\tbest: 1663.3448231 (1300)\ttotal: 8m 55s\tremaining: 1m 21s\n",
            "1400:\tlearn: 893.5496040\ttest: 1662.7988818\tbest: 1662.7988818 (1400)\ttotal: 9m 35s\tremaining: 40.7s\n",
            "1499:\tlearn: 870.5035734\ttest: 1661.5411149\tbest: 1661.4965603 (1498)\ttotal: 10m 15s\tremaining: 0us\n",
            "bestTest = 1661.49656\n",
            "bestIteration = 1498\n",
            "Shrink model to first 1499 iterations.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training CatBoost Models: 100%|██████████| 6/6 [1:06:52<00:00, 668.71s/it]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train CatBoost models\n",
        "catboost_models = [CatBoostRegressor(iterations=1500, depth=8, learning_rate=0.1, loss_function='RMSE', task_type=\"GPU\", devices='0') for _ in range(6)]\n",
        "catboost_predictions_val = []\n",
        "\n",
        "for i in tqdm(range(6), desc=\"Training CatBoost Models\"):\n",
        "    catboost_models[i].fit(X_train, y_train[:, i], eval_set=(X_val, y_val[:, i]), verbose=100)\n",
        "    catboost_predictions_val.append(catboost_models[i].predict(X_val))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xX7zvrKIRmX",
        "outputId": "ad18096c-03ab-480b-eb67-360c0e831b6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combination: CatBoost | R2 Score: 0.4237\n",
            "Combination: XGBoost | R2 Score: 0.4062\n",
            "Combination: LightGBM | R2 Score: 0.4238\n",
            "Combination: CatBoost, XGBoost | R2 Score: 0.4378\n",
            "Combination: CatBoost, LightGBM | R2 Score: 0.4395\n",
            "Combination: XGBoost, LightGBM | R2 Score: 0.4369\n",
            "Combination: CatBoost, XGBoost, LightGBM | R2 Score: 0.4448\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate a list of all models' validation predictions\n",
        "all_predictions_val = [np.array(catboost_predictions_val).T,\n",
        "                       np.array(xgboost_predictions_val).T,\n",
        "                       np.array(lightgbm_predictions_val).T]\n",
        "\n",
        "# Create a list of model names for reference\n",
        "model_names = ['CatBoost', 'XGBoost', 'LightGBM']\n",
        "\n",
        "# Initialize a dictionary to store R2 scores for each combination\n",
        "r2_scores = {}\n",
        "\n",
        "# Iterate over all possible non-empty combinations of the 3 models\n",
        "for r in range(1, 4):\n",
        "    for combo in combinations(range(3), r):\n",
        "        # Select the corresponding predictions\n",
        "        selected_predictions = [all_predictions_val[i] for i in combo]\n",
        "\n",
        "        # Combine selected predictions into meta-features\n",
        "        val_meta_features = np.column_stack(selected_predictions)\n",
        "\n",
        "        # Train the meta-model (e.g., Linear Regression)\n",
        "        meta_model = LinearRegression()\n",
        "        meta_model.fit(val_meta_features, y_val)\n",
        "\n",
        "        # Predict using the meta-model on the validation set\n",
        "        val_meta_pred = meta_model.predict(val_meta_features)\n",
        "\n",
        "        # Evaluate the performance of the meta-model\n",
        "        meta_r2_score = r2_score(y_val, val_meta_pred)\n",
        "\n",
        "        # Store the R2 score with the corresponding model names\n",
        "        combo_names = [model_names[i] for i in combo]\n",
        "        r2_scores[', '.join(combo_names)] = meta_r2_score\n",
        "\n",
        "# Display the R2 scores for all combinations\n",
        "for combo, score in r2_scores.items():\n",
        "    print(f\"Combination: {combo} | R2 Score: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQTez8m2IOgP",
        "outputId": "a1eed984-ac7a-4a33-aa50-4db0f5a10a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meta-model R2 Score (using all 3 models): 0.4448\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Combine predictions for validation set using all three models\n",
        "val_meta_features = np.column_stack((\n",
        "    np.array(catboost_predictions_val).T,\n",
        "    np.array(xgboost_predictions_val).T,\n",
        "    np.array(lightgbm_predictions_val).T\n",
        "))\n",
        "\n",
        "# Train the meta-model (e.g., Linear Regression)\n",
        "meta_model = LinearRegression()\n",
        "meta_model.fit(val_meta_features, y_val)\n",
        "\n",
        "# Predict using the meta-model on the validation set\n",
        "val_meta_pred = meta_model.predict(val_meta_features)\n",
        "\n",
        "# Evaluate the performance of the meta-model\n",
        "meta_r2_score = r2_score(y_val, val_meta_pred)\n",
        "print(f\"Meta-model R2 Score (using all 3 models): {meta_r2_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bKhcFRGIL-g",
        "outputId": "7038c76d-3d67-4ac7-b36b-a33a96631182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file generated successfully.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Generate predictions for the test set using each model\n",
        "test_predictions_catboost = []\n",
        "test_predictions_xgboost = []\n",
        "test_predictions_lightgbm = []\n",
        "\n",
        "X_test = test_full_feature_df.iloc[:, 1:]\n",
        "\n",
        "for i in range(6):\n",
        "    test_predictions_catboost.append(catboost_models[i].predict(X_test.values))\n",
        "    test_predictions_xgboost.append(xgboost_models[i].predict(X_test.values))\n",
        "    test_predictions_lightgbm.append(lightgbm_models[i].predict(X_test.values))\n",
        "\n",
        "# Step 2: Combine the test predictions to create meta-features\n",
        "test_meta_features = np.column_stack((\n",
        "    np.array(test_predictions_catboost).T,\n",
        "    np.array(test_predictions_xgboost).T,\n",
        "    np.array(test_predictions_lightgbm).T\n",
        "))\n",
        "\n",
        "# Step 3: Generate final predictions using the meta-model\n",
        "test_meta_pred = meta_model.predict(test_meta_features)\n",
        "\n",
        "# Step 4: Prepare the submission file\n",
        "submission_df = pd.DataFrame(test_meta_pred, columns=['X4', 'X11', 'X18', 'X26', 'X50', 'X3112'])\n",
        "submission_df.insert(0, 'id', test_df['id'])\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file generated successfully.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
